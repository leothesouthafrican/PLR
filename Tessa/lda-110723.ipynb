{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDAmodel\n",
    "from sklearn.model_selection import KFold, ParameterGrid, GridSearchCV\n",
    "import seaborn as sns\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cleaned_data_SYMPTOMS_9_13_23.csv\", index_col=0)\n",
    "sympdf = df.loc[:, df.columns.str.startswith('Symptom_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_components': [3, 4, 5, 6, 7],\n",
    "    'learning_method': ['batch'],\n",
    "    'random_state': [42],\n",
    "    'max_iter': [5, 10, 20],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_method': 'batch', 'max_iter': 5, 'n_components': 3, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 5, 'n_components': 4, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 5, 'n_components': 5, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 5, 'n_components': 6, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 5, 'n_components': 7, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 10, 'n_components': 3, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 10, 'n_components': 4, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 10, 'n_components': 5, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 10, 'n_components': 6, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 10, 'n_components': 7, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 20, 'n_components': 3, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 20, 'n_components': 4, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 20, 'n_components': 5, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 20, 'n_components': 6, 'random_state': 42}\n",
      "{'learning_method': 'batch', 'max_iter': 20, 'n_components': 7, 'random_state': 42}\n",
      "Best hyperparameters: {'learning_method': 'batch', 'max_iter': 20, 'n_components': 3, 'random_state': 42}\n",
      "Best average perplexity: 133.0275850554372\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "results = {}  # To store results\n",
    "\n",
    "for hyperparameters in ParameterGrid(param_grid):\n",
    "    print(hyperparameters)\n",
    "    total_perplexity = 0\n",
    "    lda = LDAmodel(**hyperparameters)\n",
    "    \n",
    "    perplexities = []  # To store perplexity values for each fold\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(sympdf), 1):\n",
    "        train_data = sympdf.iloc[train_index]\n",
    "        val_data = sympdf.iloc[val_index]\n",
    "        \n",
    "        lda.fit(train_data)\n",
    "        perplexity = lda.perplexity(val_data)\n",
    "        perplexities.append(perplexity)\n",
    "\n",
    "    average_perplexity = np.mean(perplexities)\n",
    "\n",
    "    # Store the results\n",
    "    results[str(hyperparameters)] = {\n",
    "        \"average_perplexity\": average_perplexity,\n",
    "        \"perplexities\": perplexities\n",
    "    }\n",
    "\n",
    "# Find the best hyperparameters based on average perplexity\n",
    "best_hyperparameters = min(results, key=lambda x: results[x][\"average_perplexity\"])\n",
    "best_average_perplexity = results[best_hyperparameters][\"average_perplexity\"]\n",
    "\n",
    "print(\"Best hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best average perplexity:\", best_average_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a pkl file of results\n",
    "with open('output/lda_results-4.pkl', 'wb') as f:\n",
    "    pkl.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'n_components': 10, 'learning_decay': 0.9}\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performed well with a default learning decay, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the average_perplexities into a dataframe\n",
    "df = pd.DataFrame.from_dict(results, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='average_perplexity', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_perplexity</th>\n",
       "      <th>perplexities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 20, 'n_components': 3, 'random_state': 42}</th>\n",
       "      <td>133.027585</td>\n",
       "      <td>[132.6451185286299, 132.86677982910615, 133.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 10, 'n_components': 3, 'random_state': 42}</th>\n",
       "      <td>133.559102</td>\n",
       "      <td>[133.20260966265667, 133.45574274326054, 133.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 5, 'n_components': 3, 'random_state': 42}</th>\n",
       "      <td>135.459295</td>\n",
       "      <td>[135.107787124454, 135.47688330452698, 135.886...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 20, 'n_components': 4, 'random_state': 42}</th>\n",
       "      <td>136.031815</td>\n",
       "      <td>[135.82686061987795, 135.72110708919075, 136.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 10, 'n_components': 4, 'random_state': 42}</th>\n",
       "      <td>136.417750</td>\n",
       "      <td>[136.1859146159476, 136.12856546788757, 136.71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 5, 'n_components': 4, 'random_state': 42}</th>\n",
       "      <td>137.414989</td>\n",
       "      <td>[137.1714754909619, 137.19849219990073, 137.70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 20, 'n_components': 5, 'random_state': 42}</th>\n",
       "      <td>138.621205</td>\n",
       "      <td>[138.59161110991235, 138.4524391366244, 138.74...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 10, 'n_components': 5, 'random_state': 42}</th>\n",
       "      <td>139.206151</td>\n",
       "      <td>[139.2100476223345, 138.95417047699462, 139.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 5, 'n_components': 5, 'random_state': 42}</th>\n",
       "      <td>140.419156</td>\n",
       "      <td>[140.3827892418617, 140.11843621605814, 140.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 20, 'n_components': 6, 'random_state': 42}</th>\n",
       "      <td>141.379701</td>\n",
       "      <td>[141.29878215806875, 141.30779888897487, 141.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 10, 'n_components': 6, 'random_state': 42}</th>\n",
       "      <td>141.779185</td>\n",
       "      <td>[141.6951342785997, 141.6299838361356, 141.971...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 5, 'n_components': 6, 'random_state': 42}</th>\n",
       "      <td>142.672266</td>\n",
       "      <td>[142.5480523659768, 142.605385168076, 142.9203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 20, 'n_components': 7, 'random_state': 42}</th>\n",
       "      <td>144.035271</td>\n",
       "      <td>[144.02832691216938, 143.9572928906513, 144.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 10, 'n_components': 7, 'random_state': 42}</th>\n",
       "      <td>144.373024</td>\n",
       "      <td>[144.26393296874915, 144.2557128176617, 144.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'learning_method': 'batch', 'max_iter': 5, 'n_components': 7, 'random_state': 42}</th>\n",
       "      <td>145.249676</td>\n",
       "      <td>[145.12645190786273, 145.11532922198091, 145.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    average_perplexity  \\\n",
       "{'learning_method': 'batch', 'max_iter': 20, 'n...          133.027585   \n",
       "{'learning_method': 'batch', 'max_iter': 10, 'n...          133.559102   \n",
       "{'learning_method': 'batch', 'max_iter': 5, 'n_...          135.459295   \n",
       "{'learning_method': 'batch', 'max_iter': 20, 'n...          136.031815   \n",
       "{'learning_method': 'batch', 'max_iter': 10, 'n...          136.417750   \n",
       "{'learning_method': 'batch', 'max_iter': 5, 'n_...          137.414989   \n",
       "{'learning_method': 'batch', 'max_iter': 20, 'n...          138.621205   \n",
       "{'learning_method': 'batch', 'max_iter': 10, 'n...          139.206151   \n",
       "{'learning_method': 'batch', 'max_iter': 5, 'n_...          140.419156   \n",
       "{'learning_method': 'batch', 'max_iter': 20, 'n...          141.379701   \n",
       "{'learning_method': 'batch', 'max_iter': 10, 'n...          141.779185   \n",
       "{'learning_method': 'batch', 'max_iter': 5, 'n_...          142.672266   \n",
       "{'learning_method': 'batch', 'max_iter': 20, 'n...          144.035271   \n",
       "{'learning_method': 'batch', 'max_iter': 10, 'n...          144.373024   \n",
       "{'learning_method': 'batch', 'max_iter': 5, 'n_...          145.249676   \n",
       "\n",
       "                                                                                         perplexities  \n",
       "{'learning_method': 'batch', 'max_iter': 20, 'n...  [132.6451185286299, 132.86677982910615, 133.07...  \n",
       "{'learning_method': 'batch', 'max_iter': 10, 'n...  [133.20260966265667, 133.45574274326054, 133.7...  \n",
       "{'learning_method': 'batch', 'max_iter': 5, 'n_...  [135.107787124454, 135.47688330452698, 135.886...  \n",
       "{'learning_method': 'batch', 'max_iter': 20, 'n...  [135.82686061987795, 135.72110708919075, 136.2...  \n",
       "{'learning_method': 'batch', 'max_iter': 10, 'n...  [136.1859146159476, 136.12856546788757, 136.71...  \n",
       "{'learning_method': 'batch', 'max_iter': 5, 'n_...  [137.1714754909619, 137.19849219990073, 137.70...  \n",
       "{'learning_method': 'batch', 'max_iter': 20, 'n...  [138.59161110991235, 138.4524391366244, 138.74...  \n",
       "{'learning_method': 'batch', 'max_iter': 10, 'n...  [139.2100476223345, 138.95417047699462, 139.33...  \n",
       "{'learning_method': 'batch', 'max_iter': 5, 'n_...  [140.3827892418617, 140.11843621605814, 140.47...  \n",
       "{'learning_method': 'batch', 'max_iter': 20, 'n...  [141.29878215806875, 141.30779888897487, 141.5...  \n",
       "{'learning_method': 'batch', 'max_iter': 10, 'n...  [141.6951342785997, 141.6299838361356, 141.971...  \n",
       "{'learning_method': 'batch', 'max_iter': 5, 'n_...  [142.5480523659768, 142.605385168076, 142.9203...  \n",
       "{'learning_method': 'batch', 'max_iter': 20, 'n...  [144.02832691216938, 143.9572928906513, 144.27...  \n",
       "{'learning_method': 'batch', 'max_iter': 10, 'n...  [144.26393296874915, 144.2557128176617, 144.51...  \n",
       "{'learning_method': 'batch', 'max_iter': 5, 'n_...  [145.12645190786273, 145.11532922198091, 145.4...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "# takeaway: n_components of 4 is across the board the best performing \n",
    "# What does it mean that I'm getting the same values? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typically, you'd expect more topics means more model capacity \n",
    "# so why is my perplexity dropping? \n",
    "# are some patients having really poor fit? \n",
    "# or maybe need to do symptom pruning analogous to stopwords\n",
    "\n",
    "# symptom absence tells you something about a patient\n",
    "\n",
    "# think about different prior? \n",
    "# \n",
    "\n",
    "#doc_topic_priorfloat, default=None\n",
    "#Prior of document topic distribution theta. If the value is None, defaults to 1 / n_components. In [1], this is called alpha.\n",
    "# dirichlet prior -- flat by default\n",
    "# if we have reason to believe docs are spiky, you'd want this to be a lower value \n",
    "# try running with (0.5,0.5,0.5 , ... ) and look if this is input as a number or a vector\n",
    "\n",
    "#topic_word_priorfloat, default=None\n",
    "#Prior of topic word distribution beta. If the value is None, defaults to 1 / n_components. In [1], this is called eta.\n",
    "# leave this -- expectation is mixed\n",
    "# should probably be 1/n_words (/library size) but look at the implementation bc this seems weird\n",
    "\n",
    "\n",
    "# possible issues: model is a poor fit for the data (which we know) so perplexity might not be the best readout\n",
    "# priors might be off\n",
    "# need to look at the topics themselves and the topic dists for patients and see if they make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={&#x27;learning_method&#x27;: [&#x27;batch&#x27;],\n",
       "                         &#x27;max_iter&#x27;: [60, 90, 120, 150, 180],\n",
       "                         &#x27;n_components&#x27;: [3, 4, 5, 6, 7, 8, 9],\n",
       "                         &#x27;random_state&#x27;: [42]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={&#x27;learning_method&#x27;: [&#x27;batch&#x27;],\n",
       "                         &#x27;max_iter&#x27;: [60, 90, 120, 150, 180],\n",
       "                         &#x27;n_components&#x27;: [3, 4, 5, 6, 7, 8, 9],\n",
       "                         &#x27;random_state&#x27;: [42]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={'learning_method': ['batch'],\n",
       "                         'max_iter': [60, 90, 120, 150, 180],\n",
       "                         'n_components': [3, 4, 5, 6, 7, 8, 9],\n",
       "                         'random_state': [42]})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_components': [3, 4, 5, 6, 7,8,9],\n",
    "    'learning_method': ['batch'],\n",
    "    'random_state': [42],\n",
    "    'max_iter': [60,90,120,150,180],\n",
    "}\n",
    "\n",
    "# no gaussians or whatever, so n_steps can just be 1 \n",
    "\n",
    "# Init the Model\n",
    "lda = LDAmodel()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=param_grid)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(sympdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_method': 'batch',\n",
       " 'max_iter': 180,\n",
       " 'n_components': 3,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsres = pd.DataFrame(model.cv_results_)\n",
    "gsres.to_csv(\"output/lda-gridsearch-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_method</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_n_components</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.834458</td>\n",
       "      <td>3.426613</td>\n",
       "      <td>0.203918</td>\n",
       "      <td>0.017070</td>\n",
       "      <td>batch</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 60, '...</td>\n",
       "      <td>-278064.688238</td>\n",
       "      <td>-263563.143617</td>\n",
       "      <td>-269825.635942</td>\n",
       "      <td>-254873.427444</td>\n",
       "      <td>-262050.717538</td>\n",
       "      <td>-265675.522556</td>\n",
       "      <td>7810.268656</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.614303</td>\n",
       "      <td>0.287657</td>\n",
       "      <td>0.188179</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>batch</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 60, '...</td>\n",
       "      <td>-279454.237307</td>\n",
       "      <td>-264621.759329</td>\n",
       "      <td>-271221.087701</td>\n",
       "      <td>-256152.413035</td>\n",
       "      <td>-263306.437180</td>\n",
       "      <td>-266951.186910</td>\n",
       "      <td>7872.512593</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.811641</td>\n",
       "      <td>0.454723</td>\n",
       "      <td>0.204991</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>batch</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 60, '...</td>\n",
       "      <td>-280345.537064</td>\n",
       "      <td>-265642.321164</td>\n",
       "      <td>-272024.938768</td>\n",
       "      <td>-257078.284026</td>\n",
       "      <td>-264089.034515</td>\n",
       "      <td>-267836.023108</td>\n",
       "      <td>7856.413377</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.484045</td>\n",
       "      <td>0.619138</td>\n",
       "      <td>0.217031</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>batch</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 60, '...</td>\n",
       "      <td>-281480.386541</td>\n",
       "      <td>-266513.915076</td>\n",
       "      <td>-273048.447951</td>\n",
       "      <td>-258020.871380</td>\n",
       "      <td>-265007.483017</td>\n",
       "      <td>-268814.220793</td>\n",
       "      <td>7932.710568</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.607311</td>\n",
       "      <td>1.419578</td>\n",
       "      <td>0.227927</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>batch</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 60, '...</td>\n",
       "      <td>-282504.818715</td>\n",
       "      <td>-267428.390129</td>\n",
       "      <td>-274116.993770</td>\n",
       "      <td>-258884.634934</td>\n",
       "      <td>-265804.871526</td>\n",
       "      <td>-269747.941815</td>\n",
       "      <td>8009.570312</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52.856849</td>\n",
       "      <td>0.990550</td>\n",
       "      <td>0.217738</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>batch</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 60, '...</td>\n",
       "      <td>-282968.165610</td>\n",
       "      <td>-267969.425818</td>\n",
       "      <td>-274639.407581</td>\n",
       "      <td>-259494.891620</td>\n",
       "      <td>-266326.010214</td>\n",
       "      <td>-270279.580169</td>\n",
       "      <td>7965.994366</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52.859523</td>\n",
       "      <td>0.806215</td>\n",
       "      <td>0.219785</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>batch</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 60, '...</td>\n",
       "      <td>-283250.836715</td>\n",
       "      <td>-268692.730400</td>\n",
       "      <td>-275179.575197</td>\n",
       "      <td>-260039.540028</td>\n",
       "      <td>-266539.120295</td>\n",
       "      <td>-270740.360527</td>\n",
       "      <td>7906.572068</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78.401409</td>\n",
       "      <td>4.802406</td>\n",
       "      <td>0.192181</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>batch</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 90, '...</td>\n",
       "      <td>-278044.717242</td>\n",
       "      <td>-263376.803991</td>\n",
       "      <td>-269813.033960</td>\n",
       "      <td>-254863.638528</td>\n",
       "      <td>-262000.595605</td>\n",
       "      <td>-265619.757865</td>\n",
       "      <td>7820.312790</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67.508000</td>\n",
       "      <td>0.734093</td>\n",
       "      <td>0.189184</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>batch</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 90, '...</td>\n",
       "      <td>-279397.988889</td>\n",
       "      <td>-264575.959633</td>\n",
       "      <td>-271195.551267</td>\n",
       "      <td>-256069.596092</td>\n",
       "      <td>-263276.307746</td>\n",
       "      <td>-266903.080726</td>\n",
       "      <td>7880.119257</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72.234653</td>\n",
       "      <td>0.949666</td>\n",
       "      <td>0.203363</td>\n",
       "      <td>0.011015</td>\n",
       "      <td>batch</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 90, '...</td>\n",
       "      <td>-280273.316614</td>\n",
       "      <td>-265489.599276</td>\n",
       "      <td>-271898.680860</td>\n",
       "      <td>-256951.603300</td>\n",
       "      <td>-263999.304382</td>\n",
       "      <td>-267722.500887</td>\n",
       "      <td>7871.768940</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>77.341810</td>\n",
       "      <td>0.792109</td>\n",
       "      <td>0.217156</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>batch</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 90, '...</td>\n",
       "      <td>-281372.598496</td>\n",
       "      <td>-266389.859225</td>\n",
       "      <td>-272929.196647</td>\n",
       "      <td>-257908.680474</td>\n",
       "      <td>-264913.341147</td>\n",
       "      <td>-268702.735198</td>\n",
       "      <td>7932.325413</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>81.484744</td>\n",
       "      <td>2.535636</td>\n",
       "      <td>0.225638</td>\n",
       "      <td>0.013351</td>\n",
       "      <td>batch</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 90, '...</td>\n",
       "      <td>-282237.455326</td>\n",
       "      <td>-267319.878981</td>\n",
       "      <td>-273919.421691</td>\n",
       "      <td>-258657.503673</td>\n",
       "      <td>-265461.318782</td>\n",
       "      <td>-269519.115691</td>\n",
       "      <td>8004.946339</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>76.809004</td>\n",
       "      <td>1.658893</td>\n",
       "      <td>0.215234</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>batch</td>\n",
       "      <td>90</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 90, '...</td>\n",
       "      <td>-282785.525409</td>\n",
       "      <td>-267701.252003</td>\n",
       "      <td>-274419.714388</td>\n",
       "      <td>-259239.854991</td>\n",
       "      <td>-266078.556001</td>\n",
       "      <td>-270044.980558</td>\n",
       "      <td>7992.948205</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>76.464863</td>\n",
       "      <td>1.200357</td>\n",
       "      <td>0.217955</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>batch</td>\n",
       "      <td>90</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 90, '...</td>\n",
       "      <td>-283044.050604</td>\n",
       "      <td>-268351.589645</td>\n",
       "      <td>-274895.222092</td>\n",
       "      <td>-259842.354150</td>\n",
       "      <td>-266342.792863</td>\n",
       "      <td>-270495.201871</td>\n",
       "      <td>7901.322940</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>99.639558</td>\n",
       "      <td>5.469801</td>\n",
       "      <td>0.186498</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>batch</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 120, ...</td>\n",
       "      <td>-278037.336849</td>\n",
       "      <td>-263337.854738</td>\n",
       "      <td>-269807.401881</td>\n",
       "      <td>-254854.086266</td>\n",
       "      <td>-261949.914562</td>\n",
       "      <td>-265597.318859</td>\n",
       "      <td>7826.935919</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>88.610579</td>\n",
       "      <td>1.476461</td>\n",
       "      <td>0.190540</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>batch</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 120, ...</td>\n",
       "      <td>-279359.367945</td>\n",
       "      <td>-264521.796249</td>\n",
       "      <td>-271167.521994</td>\n",
       "      <td>-256000.651470</td>\n",
       "      <td>-263243.596525</td>\n",
       "      <td>-266858.586837</td>\n",
       "      <td>7889.993107</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>94.416875</td>\n",
       "      <td>1.846054</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>batch</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 120, ...</td>\n",
       "      <td>-280201.617968</td>\n",
       "      <td>-265348.273959</td>\n",
       "      <td>-271792.085075</td>\n",
       "      <td>-256847.659234</td>\n",
       "      <td>-263939.185331</td>\n",
       "      <td>-267625.764313</td>\n",
       "      <td>7879.793143</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>101.036924</td>\n",
       "      <td>1.275963</td>\n",
       "      <td>0.215959</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>batch</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 120, ...</td>\n",
       "      <td>-281287.059499</td>\n",
       "      <td>-266336.562685</td>\n",
       "      <td>-272843.643058</td>\n",
       "      <td>-257774.848822</td>\n",
       "      <td>-264842.150595</td>\n",
       "      <td>-268616.852932</td>\n",
       "      <td>7942.254638</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>106.062268</td>\n",
       "      <td>3.387119</td>\n",
       "      <td>0.219362</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>batch</td>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 120, ...</td>\n",
       "      <td>-282119.051457</td>\n",
       "      <td>-267249.979587</td>\n",
       "      <td>-273767.758237</td>\n",
       "      <td>-258462.048024</td>\n",
       "      <td>-265282.031010</td>\n",
       "      <td>-269376.173663</td>\n",
       "      <td>8025.805795</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100.013728</td>\n",
       "      <td>2.264948</td>\n",
       "      <td>0.213976</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>batch</td>\n",
       "      <td>120</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 120, ...</td>\n",
       "      <td>-282644.195509</td>\n",
       "      <td>-267489.051326</td>\n",
       "      <td>-274335.315981</td>\n",
       "      <td>-259085.771833</td>\n",
       "      <td>-266026.712038</td>\n",
       "      <td>-269916.209337</td>\n",
       "      <td>7998.097240</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100.135418</td>\n",
       "      <td>1.961565</td>\n",
       "      <td>0.217629</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>batch</td>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 120, ...</td>\n",
       "      <td>-282838.625631</td>\n",
       "      <td>-268117.930354</td>\n",
       "      <td>-274735.111184</td>\n",
       "      <td>-259789.770258</td>\n",
       "      <td>-266285.523294</td>\n",
       "      <td>-270353.392144</td>\n",
       "      <td>7851.311619</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>121.078785</td>\n",
       "      <td>6.121218</td>\n",
       "      <td>0.185837</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>batch</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 150, ...</td>\n",
       "      <td>-278034.378468</td>\n",
       "      <td>-263329.837510</td>\n",
       "      <td>-269803.906333</td>\n",
       "      <td>-254848.194068</td>\n",
       "      <td>-261929.548286</td>\n",
       "      <td>-265589.172933</td>\n",
       "      <td>7829.600176</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>109.369212</td>\n",
       "      <td>1.549958</td>\n",
       "      <td>0.191057</td>\n",
       "      <td>0.005125</td>\n",
       "      <td>batch</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 150, ...</td>\n",
       "      <td>-279294.909941</td>\n",
       "      <td>-264490.569086</td>\n",
       "      <td>-271097.929263</td>\n",
       "      <td>-255948.119997</td>\n",
       "      <td>-263216.818257</td>\n",
       "      <td>-266809.669309</td>\n",
       "      <td>7880.741908</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>117.098948</td>\n",
       "      <td>2.386645</td>\n",
       "      <td>0.204415</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>batch</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 150, ...</td>\n",
       "      <td>-280124.626257</td>\n",
       "      <td>-265278.135622</td>\n",
       "      <td>-271705.816709</td>\n",
       "      <td>-256781.549321</td>\n",
       "      <td>-263882.749963</td>\n",
       "      <td>-267554.575574</td>\n",
       "      <td>7873.519593</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>124.922159</td>\n",
       "      <td>1.278722</td>\n",
       "      <td>0.216465</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>batch</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 150, ...</td>\n",
       "      <td>-281231.308811</td>\n",
       "      <td>-266259.683196</td>\n",
       "      <td>-272799.333558</td>\n",
       "      <td>-257684.138952</td>\n",
       "      <td>-264794.638678</td>\n",
       "      <td>-268553.820639</td>\n",
       "      <td>7953.459397</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>129.852553</td>\n",
       "      <td>4.769333</td>\n",
       "      <td>0.219555</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>batch</td>\n",
       "      <td>150</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 150, ...</td>\n",
       "      <td>-282081.352665</td>\n",
       "      <td>-267175.787040</td>\n",
       "      <td>-273658.006727</td>\n",
       "      <td>-258369.674770</td>\n",
       "      <td>-265208.771631</td>\n",
       "      <td>-269298.718567</td>\n",
       "      <td>8038.378322</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>123.964252</td>\n",
       "      <td>3.515634</td>\n",
       "      <td>0.213569</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>batch</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 150, ...</td>\n",
       "      <td>-282513.872315</td>\n",
       "      <td>-267409.510732</td>\n",
       "      <td>-274263.307104</td>\n",
       "      <td>-258915.204086</td>\n",
       "      <td>-266012.127988</td>\n",
       "      <td>-269822.804445</td>\n",
       "      <td>8001.278082</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>123.769623</td>\n",
       "      <td>2.336314</td>\n",
       "      <td>0.217164</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>batch</td>\n",
       "      <td>150</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 150, ...</td>\n",
       "      <td>-282713.156389</td>\n",
       "      <td>-268023.203631</td>\n",
       "      <td>-274666.484592</td>\n",
       "      <td>-259713.464826</td>\n",
       "      <td>-266253.244184</td>\n",
       "      <td>-270273.910725</td>\n",
       "      <td>7833.058117</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>142.090194</td>\n",
       "      <td>6.492295</td>\n",
       "      <td>0.185077</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>batch</td>\n",
       "      <td>180</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 180, ...</td>\n",
       "      <td>-278032.442337</td>\n",
       "      <td>-263324.252783</td>\n",
       "      <td>-269799.874736</td>\n",
       "      <td>-254845.160209</td>\n",
       "      <td>-261898.736341</td>\n",
       "      <td>-265580.093281</td>\n",
       "      <td>7832.592749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>130.880388</td>\n",
       "      <td>2.139667</td>\n",
       "      <td>0.192775</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>batch</td>\n",
       "      <td>180</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 180, ...</td>\n",
       "      <td>-279239.349469</td>\n",
       "      <td>-264461.448052</td>\n",
       "      <td>-271046.949029</td>\n",
       "      <td>-255915.140898</td>\n",
       "      <td>-263166.605089</td>\n",
       "      <td>-266765.898507</td>\n",
       "      <td>7872.975526</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>139.343240</td>\n",
       "      <td>3.020713</td>\n",
       "      <td>0.203603</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>batch</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 180, ...</td>\n",
       "      <td>-280066.473416</td>\n",
       "      <td>-265237.758665</td>\n",
       "      <td>-271651.374367</td>\n",
       "      <td>-256735.598213</td>\n",
       "      <td>-263831.230108</td>\n",
       "      <td>-267504.486954</td>\n",
       "      <td>7868.926443</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>148.412801</td>\n",
       "      <td>1.796812</td>\n",
       "      <td>0.215732</td>\n",
       "      <td>0.008535</td>\n",
       "      <td>batch</td>\n",
       "      <td>180</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 180, ...</td>\n",
       "      <td>-281186.119010</td>\n",
       "      <td>-266166.126177</td>\n",
       "      <td>-272743.234279</td>\n",
       "      <td>-257617.182909</td>\n",
       "      <td>-264782.371909</td>\n",
       "      <td>-268499.006857</td>\n",
       "      <td>7957.965584</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>154.511056</td>\n",
       "      <td>5.719649</td>\n",
       "      <td>0.219645</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>batch</td>\n",
       "      <td>180</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 180, ...</td>\n",
       "      <td>-282020.974263</td>\n",
       "      <td>-267068.290056</td>\n",
       "      <td>-273587.660847</td>\n",
       "      <td>-258341.564191</td>\n",
       "      <td>-265185.480861</td>\n",
       "      <td>-269240.794044</td>\n",
       "      <td>8027.288551</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>146.414848</td>\n",
       "      <td>4.116080</td>\n",
       "      <td>0.210874</td>\n",
       "      <td>0.008058</td>\n",
       "      <td>batch</td>\n",
       "      <td>180</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 180, ...</td>\n",
       "      <td>-282359.554511</td>\n",
       "      <td>-267364.892749</td>\n",
       "      <td>-274209.145809</td>\n",
       "      <td>-258824.795201</td>\n",
       "      <td>-266006.299123</td>\n",
       "      <td>-269752.937479</td>\n",
       "      <td>7974.320484</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>147.177020</td>\n",
       "      <td>3.053580</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>batch</td>\n",
       "      <td>180</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>{'learning_method': 'batch', 'max_iter': 180, ...</td>\n",
       "      <td>-282670.689918</td>\n",
       "      <td>-267977.263034</td>\n",
       "      <td>-274623.689342</td>\n",
       "      <td>-259620.451082</td>\n",
       "      <td>-266235.062894</td>\n",
       "      <td>-270225.431254</td>\n",
       "      <td>7844.387061</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       56.834458      3.426613         0.203918        0.017070   \n",
       "1       46.614303      0.287657         0.188179        0.003142   \n",
       "2       49.811641      0.454723         0.204991        0.007013   \n",
       "3       53.484045      0.619138         0.217031        0.005289   \n",
       "4       56.607311      1.419578         0.227927        0.006732   \n",
       "5       52.856849      0.990550         0.217738        0.005796   \n",
       "6       52.859523      0.806215         0.219785        0.004376   \n",
       "7       78.401409      4.802406         0.192181        0.005294   \n",
       "8       67.508000      0.734093         0.189184        0.004463   \n",
       "9       72.234653      0.949666         0.203363        0.011015   \n",
       "10      77.341810      0.792109         0.217156        0.005856   \n",
       "11      81.484744      2.535636         0.225638        0.013351   \n",
       "12      76.809004      1.658893         0.215234        0.006192   \n",
       "13      76.464863      1.200357         0.217955        0.003862   \n",
       "14      99.639558      5.469801         0.186498        0.002573   \n",
       "15      88.610579      1.476461         0.190540        0.005324   \n",
       "16      94.416875      1.846054         0.203446        0.012116   \n",
       "17     101.036924      1.275963         0.215959        0.007041   \n",
       "18     106.062268      3.387119         0.219362        0.010607   \n",
       "19     100.013728      2.264948         0.213976        0.008913   \n",
       "20     100.135418      1.961565         0.217629        0.003143   \n",
       "21     121.078785      6.121218         0.185837        0.003587   \n",
       "22     109.369212      1.549958         0.191057        0.005125   \n",
       "23     117.098948      2.386645         0.204415        0.011161   \n",
       "24     124.922159      1.278722         0.216465        0.008531   \n",
       "25     129.852553      4.769333         0.219555        0.009495   \n",
       "26     123.964252      3.515634         0.213569        0.008278   \n",
       "27     123.769623      2.336314         0.217164        0.004133   \n",
       "28     142.090194      6.492295         0.185077        0.003652   \n",
       "29     130.880388      2.139667         0.192775        0.004611   \n",
       "30     139.343240      3.020713         0.203603        0.011669   \n",
       "31     148.412801      1.796812         0.215732        0.008535   \n",
       "32     154.511056      5.719649         0.219645        0.009934   \n",
       "33     146.414848      4.116080         0.210874        0.008058   \n",
       "34     147.177020      3.053580         0.217600        0.005307   \n",
       "\n",
       "   param_learning_method param_max_iter param_n_components param_random_state  \\\n",
       "0                  batch             60                  3                 42   \n",
       "1                  batch             60                  4                 42   \n",
       "2                  batch             60                  5                 42   \n",
       "3                  batch             60                  6                 42   \n",
       "4                  batch             60                  7                 42   \n",
       "5                  batch             60                  8                 42   \n",
       "6                  batch             60                  9                 42   \n",
       "7                  batch             90                  3                 42   \n",
       "8                  batch             90                  4                 42   \n",
       "9                  batch             90                  5                 42   \n",
       "10                 batch             90                  6                 42   \n",
       "11                 batch             90                  7                 42   \n",
       "12                 batch             90                  8                 42   \n",
       "13                 batch             90                  9                 42   \n",
       "14                 batch            120                  3                 42   \n",
       "15                 batch            120                  4                 42   \n",
       "16                 batch            120                  5                 42   \n",
       "17                 batch            120                  6                 42   \n",
       "18                 batch            120                  7                 42   \n",
       "19                 batch            120                  8                 42   \n",
       "20                 batch            120                  9                 42   \n",
       "21                 batch            150                  3                 42   \n",
       "22                 batch            150                  4                 42   \n",
       "23                 batch            150                  5                 42   \n",
       "24                 batch            150                  6                 42   \n",
       "25                 batch            150                  7                 42   \n",
       "26                 batch            150                  8                 42   \n",
       "27                 batch            150                  9                 42   \n",
       "28                 batch            180                  3                 42   \n",
       "29                 batch            180                  4                 42   \n",
       "30                 batch            180                  5                 42   \n",
       "31                 batch            180                  6                 42   \n",
       "32                 batch            180                  7                 42   \n",
       "33                 batch            180                  8                 42   \n",
       "34                 batch            180                  9                 42   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_method': 'batch', 'max_iter': 60, '...     -278064.688238   \n",
       "1   {'learning_method': 'batch', 'max_iter': 60, '...     -279454.237307   \n",
       "2   {'learning_method': 'batch', 'max_iter': 60, '...     -280345.537064   \n",
       "3   {'learning_method': 'batch', 'max_iter': 60, '...     -281480.386541   \n",
       "4   {'learning_method': 'batch', 'max_iter': 60, '...     -282504.818715   \n",
       "5   {'learning_method': 'batch', 'max_iter': 60, '...     -282968.165610   \n",
       "6   {'learning_method': 'batch', 'max_iter': 60, '...     -283250.836715   \n",
       "7   {'learning_method': 'batch', 'max_iter': 90, '...     -278044.717242   \n",
       "8   {'learning_method': 'batch', 'max_iter': 90, '...     -279397.988889   \n",
       "9   {'learning_method': 'batch', 'max_iter': 90, '...     -280273.316614   \n",
       "10  {'learning_method': 'batch', 'max_iter': 90, '...     -281372.598496   \n",
       "11  {'learning_method': 'batch', 'max_iter': 90, '...     -282237.455326   \n",
       "12  {'learning_method': 'batch', 'max_iter': 90, '...     -282785.525409   \n",
       "13  {'learning_method': 'batch', 'max_iter': 90, '...     -283044.050604   \n",
       "14  {'learning_method': 'batch', 'max_iter': 120, ...     -278037.336849   \n",
       "15  {'learning_method': 'batch', 'max_iter': 120, ...     -279359.367945   \n",
       "16  {'learning_method': 'batch', 'max_iter': 120, ...     -280201.617968   \n",
       "17  {'learning_method': 'batch', 'max_iter': 120, ...     -281287.059499   \n",
       "18  {'learning_method': 'batch', 'max_iter': 120, ...     -282119.051457   \n",
       "19  {'learning_method': 'batch', 'max_iter': 120, ...     -282644.195509   \n",
       "20  {'learning_method': 'batch', 'max_iter': 120, ...     -282838.625631   \n",
       "21  {'learning_method': 'batch', 'max_iter': 150, ...     -278034.378468   \n",
       "22  {'learning_method': 'batch', 'max_iter': 150, ...     -279294.909941   \n",
       "23  {'learning_method': 'batch', 'max_iter': 150, ...     -280124.626257   \n",
       "24  {'learning_method': 'batch', 'max_iter': 150, ...     -281231.308811   \n",
       "25  {'learning_method': 'batch', 'max_iter': 150, ...     -282081.352665   \n",
       "26  {'learning_method': 'batch', 'max_iter': 150, ...     -282513.872315   \n",
       "27  {'learning_method': 'batch', 'max_iter': 150, ...     -282713.156389   \n",
       "28  {'learning_method': 'batch', 'max_iter': 180, ...     -278032.442337   \n",
       "29  {'learning_method': 'batch', 'max_iter': 180, ...     -279239.349469   \n",
       "30  {'learning_method': 'batch', 'max_iter': 180, ...     -280066.473416   \n",
       "31  {'learning_method': 'batch', 'max_iter': 180, ...     -281186.119010   \n",
       "32  {'learning_method': 'batch', 'max_iter': 180, ...     -282020.974263   \n",
       "33  {'learning_method': 'batch', 'max_iter': 180, ...     -282359.554511   \n",
       "34  {'learning_method': 'batch', 'max_iter': 180, ...     -282670.689918   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0      -263563.143617     -269825.635942     -254873.427444   \n",
       "1      -264621.759329     -271221.087701     -256152.413035   \n",
       "2      -265642.321164     -272024.938768     -257078.284026   \n",
       "3      -266513.915076     -273048.447951     -258020.871380   \n",
       "4      -267428.390129     -274116.993770     -258884.634934   \n",
       "5      -267969.425818     -274639.407581     -259494.891620   \n",
       "6      -268692.730400     -275179.575197     -260039.540028   \n",
       "7      -263376.803991     -269813.033960     -254863.638528   \n",
       "8      -264575.959633     -271195.551267     -256069.596092   \n",
       "9      -265489.599276     -271898.680860     -256951.603300   \n",
       "10     -266389.859225     -272929.196647     -257908.680474   \n",
       "11     -267319.878981     -273919.421691     -258657.503673   \n",
       "12     -267701.252003     -274419.714388     -259239.854991   \n",
       "13     -268351.589645     -274895.222092     -259842.354150   \n",
       "14     -263337.854738     -269807.401881     -254854.086266   \n",
       "15     -264521.796249     -271167.521994     -256000.651470   \n",
       "16     -265348.273959     -271792.085075     -256847.659234   \n",
       "17     -266336.562685     -272843.643058     -257774.848822   \n",
       "18     -267249.979587     -273767.758237     -258462.048024   \n",
       "19     -267489.051326     -274335.315981     -259085.771833   \n",
       "20     -268117.930354     -274735.111184     -259789.770258   \n",
       "21     -263329.837510     -269803.906333     -254848.194068   \n",
       "22     -264490.569086     -271097.929263     -255948.119997   \n",
       "23     -265278.135622     -271705.816709     -256781.549321   \n",
       "24     -266259.683196     -272799.333558     -257684.138952   \n",
       "25     -267175.787040     -273658.006727     -258369.674770   \n",
       "26     -267409.510732     -274263.307104     -258915.204086   \n",
       "27     -268023.203631     -274666.484592     -259713.464826   \n",
       "28     -263324.252783     -269799.874736     -254845.160209   \n",
       "29     -264461.448052     -271046.949029     -255915.140898   \n",
       "30     -265237.758665     -271651.374367     -256735.598213   \n",
       "31     -266166.126177     -272743.234279     -257617.182909   \n",
       "32     -267068.290056     -273587.660847     -258341.564191   \n",
       "33     -267364.892749     -274209.145809     -258824.795201   \n",
       "34     -267977.263034     -274623.689342     -259620.451082   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0      -262050.717538   -265675.522556     7810.268656                5  \n",
       "1      -263306.437180   -266951.186910     7872.512593               10  \n",
       "2      -264089.034515   -267836.023108     7856.413377               15  \n",
       "3      -265007.483017   -268814.220793     7932.710568               20  \n",
       "4      -265804.871526   -269747.941815     8009.570312               25  \n",
       "5      -266326.010214   -270279.580169     7965.994366               32  \n",
       "6      -266539.120295   -270740.360527     7906.572068               35  \n",
       "7      -262000.595605   -265619.757865     7820.312790                4  \n",
       "8      -263276.307746   -266903.080726     7880.119257                9  \n",
       "9      -263999.304382   -267722.500887     7871.768940               14  \n",
       "10     -264913.341147   -268702.735198     7932.325413               19  \n",
       "11     -265461.318782   -269519.115691     8004.946339               24  \n",
       "12     -266078.556001   -270044.980558     7992.948205               29  \n",
       "13     -266342.792863   -270495.201871     7901.322940               34  \n",
       "14     -261949.914562   -265597.318859     7826.935919                3  \n",
       "15     -263243.596525   -266858.586837     7889.993107                8  \n",
       "16     -263939.185331   -267625.764313     7879.793143               13  \n",
       "17     -264842.150595   -268616.852932     7942.254638               18  \n",
       "18     -265282.031010   -269376.173663     8025.805795               23  \n",
       "19     -266026.712038   -269916.209337     7998.097240               28  \n",
       "20     -266285.523294   -270353.392144     7851.311619               33  \n",
       "21     -261929.548286   -265589.172933     7829.600176                2  \n",
       "22     -263216.818257   -266809.669309     7880.741908                7  \n",
       "23     -263882.749963   -267554.575574     7873.519593               12  \n",
       "24     -264794.638678   -268553.820639     7953.459397               17  \n",
       "25     -265208.771631   -269298.718567     8038.378322               22  \n",
       "26     -266012.127988   -269822.804445     8001.278082               27  \n",
       "27     -266253.244184   -270273.910725     7833.058117               31  \n",
       "28     -261898.736341   -265580.093281     7832.592749                1  \n",
       "29     -263166.605089   -266765.898507     7872.975526                6  \n",
       "30     -263831.230108   -267504.486954     7868.926443               11  \n",
       "31     -264782.371909   -268499.006857     7957.965584               16  \n",
       "32     -265185.480861   -269240.794044     8027.288551               21  \n",
       "33     -266006.299123   -269752.937479     7974.320484               26  \n",
       "34     -266235.062894   -270225.431254     7844.387061               30  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset columns of gsres to keepcols\n",
    "keepcols = [ 'param_max_iter', 'param_n_components', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
    "gsres = gsres[keepcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_n_components</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>-265597.318859</td>\n",
       "      <td>7826.935919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>-265619.757865</td>\n",
       "      <td>7820.312790</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>-265675.522556</td>\n",
       "      <td>7810.268656</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>-265755.828645</td>\n",
       "      <td>7813.489646</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>-266858.586837</td>\n",
       "      <td>7889.993107</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>-266903.080726</td>\n",
       "      <td>7880.119257</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>-266951.186910</td>\n",
       "      <td>7872.512593</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>-267015.841264</td>\n",
       "      <td>7868.249391</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>-267625.764313</td>\n",
       "      <td>7879.793143</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>-267722.500887</td>\n",
       "      <td>7871.768940</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>-267836.023108</td>\n",
       "      <td>7856.413377</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>-267955.944741</td>\n",
       "      <td>7867.473661</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>-268616.852932</td>\n",
       "      <td>7942.254638</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>-268702.735198</td>\n",
       "      <td>7932.325413</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>-268814.220793</td>\n",
       "      <td>7932.710568</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>-269027.231038</td>\n",
       "      <td>7922.647817</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "      <td>-269376.173663</td>\n",
       "      <td>8025.805795</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>-269519.115691</td>\n",
       "      <td>8004.946339</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>-269747.941815</td>\n",
       "      <td>8009.570312</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>120</td>\n",
       "      <td>8</td>\n",
       "      <td>-269916.209337</td>\n",
       "      <td>7998.097240</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>90</td>\n",
       "      <td>8</td>\n",
       "      <td>-270044.980558</td>\n",
       "      <td>7992.948205</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>-270055.214019</td>\n",
       "      <td>7953.899117</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>-270279.580169</td>\n",
       "      <td>7965.994366</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>-270353.392144</td>\n",
       "      <td>7851.311619</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>90</td>\n",
       "      <td>9</td>\n",
       "      <td>-270495.201871</td>\n",
       "      <td>7901.322940</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>-270669.837467</td>\n",
       "      <td>7939.140715</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>-270740.360527</td>\n",
       "      <td>7906.572068</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>-271228.311928</td>\n",
       "      <td>7916.250042</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_iter param_n_components  mean_test_score  std_test_score  \\\n",
       "21            120                  3   -265597.318859     7826.935919   \n",
       "14             90                  3   -265619.757865     7820.312790   \n",
       "7              60                  3   -265675.522556     7810.268656   \n",
       "0              30                  3   -265755.828645     7813.489646   \n",
       "22            120                  4   -266858.586837     7889.993107   \n",
       "15             90                  4   -266903.080726     7880.119257   \n",
       "8              60                  4   -266951.186910     7872.512593   \n",
       "1              30                  4   -267015.841264     7868.249391   \n",
       "23            120                  5   -267625.764313     7879.793143   \n",
       "16             90                  5   -267722.500887     7871.768940   \n",
       "9              60                  5   -267836.023108     7856.413377   \n",
       "2              30                  5   -267955.944741     7867.473661   \n",
       "24            120                  6   -268616.852932     7942.254638   \n",
       "17             90                  6   -268702.735198     7932.325413   \n",
       "10             60                  6   -268814.220793     7932.710568   \n",
       "3              30                  6   -269027.231038     7922.647817   \n",
       "25            120                  7   -269376.173663     8025.805795   \n",
       "18             90                  7   -269519.115691     8004.946339   \n",
       "11             60                  7   -269747.941815     8009.570312   \n",
       "26            120                  8   -269916.209337     7998.097240   \n",
       "19             90                  8   -270044.980558     7992.948205   \n",
       "4              30                  7   -270055.214019     7953.899117   \n",
       "12             60                  8   -270279.580169     7965.994366   \n",
       "27            120                  9   -270353.392144     7851.311619   \n",
       "20             90                  9   -270495.201871     7901.322940   \n",
       "5              30                  8   -270669.837467     7939.140715   \n",
       "13             60                  9   -270740.360527     7906.572068   \n",
       "6              30                  9   -271228.311928     7916.250042   \n",
       "\n",
       "    rank_test_score  \n",
       "21                1  \n",
       "14                2  \n",
       "7                 3  \n",
       "0                 4  \n",
       "22                5  \n",
       "15                6  \n",
       "8                 7  \n",
       "1                 8  \n",
       "23                9  \n",
       "16               10  \n",
       "9                11  \n",
       "2                12  \n",
       "24               13  \n",
       "17               14  \n",
       "10               15  \n",
       "3                16  \n",
       "25               17  \n",
       "18               18  \n",
       "11               19  \n",
       "26               20  \n",
       "19               21  \n",
       "4                22  \n",
       "12               23  \n",
       "27               24  \n",
       "20               25  \n",
       "5                26  \n",
       "13               27  \n",
       "6                28  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsres.sort_values('rank_test_score',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimfa",
   "language": "python",
   "name": "nimfa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
