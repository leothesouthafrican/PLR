{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cluster_comparison import perform_umap, perform_hdbscan, calculate_silhouette\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data and demographics DataFrames, replace these with your actual DataFrames\n",
    "raw_data = pd.read_csv('/Users/leo/Programming/PLR/Leo/data/cleaned_data_SYMPTOMS_9_13_23_DNA.csv')\n",
    "data_symp_groups = pd.read_csv('data/skew_corr_groupadd.csv', usecols=['Grouped_Neuro_Sensory', 'Grouped_Cognitive_Memory', 'Grouped_Gastrointestinal', 'Grouped_Respiratory_Cardiac', 'Grouped_Eye_Vision'])\n",
    "data_symp_groups_all = pd.read_csv('data/skew_corr_groupadd.csv')\n",
    "demographics = pd.read_csv('/Users/leo/Programming/PLR/Leo/data/non_binary_data_processed.csv')\n",
    "\n",
    "# combine demographics and data_symp_group_all \n",
    "demo_all = pd.concat([demographics, data_symp_groups_all], axis=1)\n",
    "\n",
    "# combine demographics and data_symp_group\n",
    "demo_groups = pd.concat([demographics, data_symp_groups], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 0/150 [00:00<?, ?it/s]/Users/leo/Programming/PLR/Leo/env/lib/python3.11/site-packages/umap/spectral.py:550: UserWarning: Spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/leo/Programming/PLR/Leo/env/lib/python3.11/site-packages/umap/spectral.py:550: UserWarning: Spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/leo/Programming/PLR/Leo/env/lib/python3.11/site-packages/umap/spectral.py:550: UserWarning: Spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/leo/Programming/PLR/Leo/env/lib/python3.11/site-packages/umap/spectral.py:550: UserWarning: Spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/leo/Programming/PLR/Leo/env/lib/python3.11/site-packages/umap/spectral.py:550: UserWarning: Spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/leo/Programming/PLR/Leo/env/lib/python3.11/site-packages/umap/spectral.py:550: UserWarning: Spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/leo/Programming/PLR/Leo/env/lib/python3.11/site-packages/umap/spectral.py:550: UserWarning: Spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/leo/Programming/PLR/Leo/env/lib/python3.11/site-packages/umap/spectral.py:550: UserWarning: Spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/leo/Programming/PLR/Leo/env/lib/python3.11/site-packages/umap/spectral.py:550: UserWarning: Spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n",
      "/Users/leo/Programming/PLR/Leo/env/lib/python3.11/site-packages/umap/spectral.py:550: UserWarning: Spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables for adaptive mutation\n",
    "last_best_fitness = -1\n",
    "increased_mutation_rate = 0.2\n",
    "\n",
    "# Fitness function\n",
    "def fitness(params):\n",
    "    n_neighbors, min_dist, min_cluster_size, n_components = params\n",
    "    \n",
    "    # Validate n_neighbors\n",
    "    n_neighbors = max(2, int(n_neighbors))  # Ensure n_neighbors is an integer and greater than 1\n",
    "    \n",
    "    min_cluster_size = max(2, int(min_cluster_size))\n",
    "    n_components = max(2, int(n_components))\n",
    "    min_dist = min(min_dist, 1.0)\n",
    "    \n",
    "    dataset_name, dataset = random.choice(list(datasets.items()))\n",
    "    dataset = dataset.dropna()\n",
    "    umap_result = perform_umap(dataset, n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components)\n",
    "    labels = perform_hdbscan(umap_result, min_cluster_size=min_cluster_size)\n",
    "    score = calculate_silhouette(umap_result, labels)\n",
    "    return score\n",
    "\n",
    "# Datasets to consider\n",
    "datasets = {'data_symp_groups_all': data_symp_groups_all}  # Replace with your actual dataset\n",
    "print(f\"number of features: {len(datasets['data_symp_groups_all'].columns)}\")\n",
    "# Genetic Algorithm Parameters\n",
    "population_size = 180\n",
    "n_generations = 150\n",
    "selection_rate = 0.3\n",
    "mutation_rate = 0.05\n",
    "\n",
    "# Initialize population\n",
    "population = []\n",
    "for _ in range(population_size // 4):\n",
    "    # First set of individuals (close to best performing genome)\n",
    "    population.append((0.6757706356698308, 0.04030749239323905, 29, 48))\n",
    "    population.append((0.6757706356698308, 0.04030749239323905, 38, 35))\n",
    "    \n",
    "    # Second set of individuals (random within a specific range)\n",
    "    population.append((random.uniform(0.1, 5), random.uniform(0.045, 0.75), random.randint(30, 45), random.randint(8, 22)))\n",
    "    population.append((random.uniform(6, 20), random.uniform(0.76, 1.0), random.randint(46, 50), random.randint(23, 25)))\n",
    "    \n",
    "    # Third set of individuals (another set close to best performing genome but with slight variations)\n",
    "    population.append((0.6757706356698308 + random.uniform(-0.1, 0.1), 0.04030749239323905 + random.uniform(-0.01, 0.01), 29 + random.randint(-2, 2), 48 + random.randint(-2, 2)))\n",
    "    population.append((0.6757706356698308 + random.uniform(-0.1, 0.1), 0.04030749239323905 + random.uniform(-0.01, 0.01), 38 + random.randint(-2, 2), 35 + random.randint(-2, 2)))\n",
    "\n",
    "    # Fourth set of individuals (another set of random individuals)\n",
    "    population.append((random.uniform(21, 35), random.uniform(0.26, 0.5), random.randint(21, 35), random.randint(25, 38)))\n",
    "    population.append((random.uniform(36, 45), random.uniform(0.51, 0.75), random.randint(36, 45), random.randint(39, 65)))\n",
    "\n",
    "# To store best fitness and variance for each generation\n",
    "best_fitnesses = []\n",
    "variances = []\n",
    "\n",
    "# Main GA loop\n",
    "for generation in tqdm(range(n_generations), desc=\"Generations\"):\n",
    "    # Evaluate fitness of each individual in parallel using joblib\n",
    "    scores = Parallel(n_jobs=-1)(delayed(fitness)(ind) for ind in population)\n",
    "    \n",
    "    # Store best fitness and variance\n",
    "    best_fitness = max(scores)\n",
    "    best_fitnesses.append(best_fitness)\n",
    "    variances.append(np.var(scores))\n",
    "    \n",
    "    # Adaptive mutation rate\n",
    "    if best_fitness <= last_best_fitness:\n",
    "        mutation_rate = increased_mutation_rate\n",
    "    else:\n",
    "        mutation_rate = 0.1\n",
    "    last_best_fitness = best_fitness\n",
    "    \n",
    "    # Elitism: Keep the best individual\n",
    "    best_idx = scores.index(best_fitness)\n",
    "    best_individual = population[best_idx]\n",
    "    \n",
    "    # Print the top 5 individuals\n",
    "    top5_idx = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]\n",
    "    print(f\"\\nTop 5 individuals in generation {generation+1}:\")\n",
    "    for i in top5_idx:\n",
    "        print(f\"  Genome: {population[i]}, Fitness: {scores[i]}\")\n",
    "        print(f\"    n_neighbors={population[i][0]}, min_dist={population[i][1]}, min_cluster_size={population[i][2]}, n_components={population[i][3]}\")\n",
    "    \n",
    "    # Roulette wheel selection\n",
    "    fitness_sum = sum(scores)\n",
    "    selected_population = []\n",
    "    for _ in range(int(selection_rate * population_size)):\n",
    "        pick = random.uniform(0, fitness_sum)\n",
    "        current = 0\n",
    "        for i in range(len(scores)):\n",
    "            current += scores[i]\n",
    "            if current > pick:\n",
    "                selected_population.append(population[i])\n",
    "                break\n",
    "    \n",
    "    # Crossover (mate) the selected individuals\n",
    "    children = []\n",
    "    while len(children) < population_size - len(selected_population) - 1:\n",
    "        parent1, parent2 = random.sample(selected_population, 2)\n",
    "        crossover_point = random.randint(1, len(parent1) - 1)\n",
    "        child = parent1[:crossover_point] + parent2[crossover_point:]\n",
    "        children.append(child)\n",
    "    \n",
    "    # Mutation\n",
    "    mutations = 0\n",
    "    for i in range(len(children)):\n",
    "        if random.random() < mutation_rate:\n",
    "            mutations += 1\n",
    "            mutate_pos = random.randint(0, len(children[i]) - 1)\n",
    "            new_value = random.choice([\n",
    "                random.randint(5, 50),\n",
    "                random.uniform(0.0, 1.0),\n",
    "                random.randint(5, 50),\n",
    "                random.randint(2, 25)\n",
    "            ])\n",
    "            children[i] = children[i][:mutate_pos] + (new_value,) + children[i][mutate_pos+1:]\n",
    "    \n",
    "    print(f\"Number of mutations: {mutations}\")\n",
    "    \n",
    "    # Create new population\n",
    "    population = selected_population + children\n",
    "\n",
    "    # Add the best individual back into the population\n",
    "    population.append(best_individual)\n",
    "\n",
    "# Evaluate the final population and find the best individual\n",
    "final_scores = Parallel(n_jobs=-1)(delayed(fitness)(ind) for ind in population)\n",
    "best_idx = max(range(len(final_scores)), key=lambda i: final_scores[i])\n",
    "best_individual = population[best_idx]\n",
    "\n",
    "# Print best parameters and silhouette score\n",
    "print(\"\\nBest parameters found:\")\n",
    "print(f\"  n_neighbors={best_individual[0]}, min_dist={best_individual[1]}, min_cluster_size={best_individual[2]}, n_components={best_individual[3]}\")\n",
    "print(f\"Best silhouette score: {final_scores[best_idx]}\")\n",
    "\n",
    "# Plotting the graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, n_generations + 1), best_fitnesses, label='Best Fitness')\n",
    "plt.fill_between(range(1, n_generations + 1), \n",
    "                np.array(best_fitnesses) - np.array(variances), \n",
    "                np.array(best_fitnesses) + np.array(variances), \n",
    "                color='gray', alpha=0.5, label='Variance')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Fitness')\n",
    "plt.title('Evolution of Best Fitness Over Generations')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
