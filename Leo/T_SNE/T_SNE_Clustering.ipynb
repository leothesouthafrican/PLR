{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   1%|          | 54/7200 [09:13<18:40:30,  9.41s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import hdbscan\n",
    "from sklearn.metrics import silhouette_score\n",
    "import plotly.express as px\n",
    "\n",
    "# Load datasets\n",
    "datasets = {\n",
    "    'Dataset_1': pd.read_csv(\"/Users/leo/Programming/PLR/Leo/data/dataset_1.csv\").drop(columns=['Unnamed: 0']),\n",
    "    'Dataset_2': pd.read_csv(\"/Users/leo/Programming/PLR/Leo/data/dataset_2.csv\").drop(columns=['Unnamed: 0']),\n",
    "    'Dataset_3': pd.read_csv(\"/Users/leo/Programming/PLR/Leo/data/dataset_3.csv\").drop(columns=['Unnamed: 0']),\n",
    "    'Dataset_4': pd.read_csv(\"/Users/leo/Programming/PLR/Leo/data/dataset_4.csv\").drop(columns=['Unnamed: 0'])\n",
    "}\n",
    "\n",
    "# Artificial labels for each dataset\n",
    "labels = {name: np.random.randint(0, 2, size=len(data)) for name, data in datasets.items()}\n",
    "\n",
    "# Define the range of parameters for the grid search\n",
    "n_estimators_range = [50, 100, 150, 200]\n",
    "perplexities = [5, 30, 50, 100, 150, 200]\n",
    "learning_rates = [10, 100, 200, 300, 500]\n",
    "n_iterations = [500, 1000, 2000]\n",
    "top_features_range = [10, 15, 20, 25, 30]\n",
    "\n",
    "# Calculate total combinations including datasets and top features range\n",
    "total_combinations = len(datasets) * len(n_estimators_range) * len(perplexities) * len(learning_rates) * len(n_iterations) * len(top_features_range)\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "output_dir = os.path.join(os.getcwd(), 'output')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Store the results\n",
    "results = []\n",
    "\n",
    "# Single tqdm progress bar for all combinations\n",
    "with tqdm(total=total_combinations, desc='Grid Search Progress') as pbar:\n",
    "    for dataset_name, dataset in datasets.items():\n",
    "        for n_estimators, perplexity, learning_rate, n_iter, N in product(n_estimators_range, perplexities, learning_rates, n_iterations, top_features_range):\n",
    "            # Train Random Forest with current number of estimators\n",
    "            forest = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "            forest.fit(dataset, labels[dataset_name])\n",
    "            importances = forest.feature_importances_\n",
    "            indices = np.argsort(importances)[-N:]\n",
    "            top_features = dataset.columns[indices]\n",
    "\n",
    "            # Apply t-SNE with current parameters\n",
    "            tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=learning_rate, n_iter=n_iter, random_state=42)\n",
    "            tsne_results = tsne.fit_transform(dataset[top_features])\n",
    "\n",
    "            # Apply HDBSCAN clustering\n",
    "            clusterer = hdbscan.HDBSCAN()\n",
    "            cluster_labels = clusterer.fit_predict(tsne_results)\n",
    "\n",
    "            # Compute silhouette score\n",
    "            if len(set(cluster_labels)) > 1:\n",
    "                sil_score = silhouette_score(tsne_results, cluster_labels)\n",
    "            else:\n",
    "                sil_score = None\n",
    "\n",
    "            # Store the results including top feature names and silhouette score\n",
    "            results.append({\n",
    "                'dataset': dataset_name,\n",
    "                'n_estimators': n_estimators,\n",
    "                'perplexity': perplexity,\n",
    "                'learning_rate': learning_rate,\n",
    "                'n_iter': n_iter,\n",
    "                'N_top_features': N,\n",
    "                'tsne_results': tsne_results,\n",
    "                'top_features': top_features.tolist(),\n",
    "                'silhouette_score': sil_score,\n",
    "                'cluster_labels': cluster_labels\n",
    "            })\n",
    "\n",
    "            unique_labels = np.unique(cluster_labels)\n",
    "            colors = {str(label): 'white' if label == -1 else None for label in unique_labels}\n",
    "\n",
    "            # Plot the results for the current iteration with cluster colors using Plotly\n",
    "            fig = px.scatter(\n",
    "                x=tsne_results[:, 0], y=tsne_results[:, 1], color=cluster_labels.astype(str),\n",
    "                color_discrete_map=colors,\n",
    "                labels={'color': 'Cluster'},\n",
    "                title=f\"{dataset_name} - t-SNE with RF ({n_estimators} Estimators, Top {N} Features) - Clusters\"\n",
    "            )\n",
    "            fig.update_traces(marker=dict(size=5))\n",
    "\n",
    "            # Save the figure to the output directory\n",
    "            fig_file_name = os.path.join(output_dir, f\"{dataset_name}_tsne_rf_{n_estimators}_perp_{perplexity}_lr_{learning_rate}_iter_{n_iter}_top{N}.png\")\n",
    "            fig.write_image(fig_file_name)\n",
    "\n",
    "            # Update the tqdm progress bar\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
