{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f69f860-0864-4572-8ec0-c879972a64d3",
   "metadata": {},
   "source": [
    "#### In this notebook we develop a pipeline for hyperparameter tuning for UMAP + HDBSCAN.\n",
    "\n",
    "We need to tune the following params:\n",
    "\n",
    "UMAP:\n",
    "- n_neighbors: [2, 0.25*len(df)]\n",
    "- min_dist: [0, 0.99]\n",
    "- n_components: [2, n_features]\n",
    "- metric: [9 metrics for binary data]\n",
    "\n",
    "HDBSCAN:\n",
    "- min_cluster_size:\n",
    "- min_samples: \n",
    "Note: If you wish to explore different min_cluster_size settings with a fixed min_samples value, especially for larger dataset sizes, you can cache the hard computation, and recompute only the relatively cheap flat cluster extraction using the memory parameter, which makes use of joblib\n",
    "- cluster_selection_epsilon: ?\n",
    "[- alpha]X\n",
    "[- leaf clustering, not EOM]\n",
    "\n",
    "\n",
    "##### Here we use the DBCV score, but could try others?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55db4eab-d151-4738-a7f3-f3ad0674dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8599b5-5061-43d1-966e-b01b39338a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import load_symptom_data\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b3aedf4-1c61-4930-b872-2e1e9ade306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_symptom_data('../data/cleaned_data_SYMPTOMS_9_13_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf350e2-bb04-423c-84a7-6d34dd9f0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b02071-a4a9-4462-9346-c8db8bcb801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search = RandomizedSearchCV(\n",
    "#     hdb,\n",
    "#     param_distributions=hyper_params,\n",
    "#     n_iter=n_iter,\n",
    "#     scoring=clustering_score,\n",
    "#     random_state=RANDOM_SEED\n",
    "# )\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     hdb,\n",
    "#     param_grid=hyper_params,\n",
    "#     scoring=clustering_score\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f42df7f7-7fb5-496e-8e9d-89d2234113cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# random_search.fit(df)\n",
    "# elapsed_time = time.time() - start_time\n",
    "# print(\"%d fits took %.1f minutes\" % (n_iter, elapsed_time/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb80f053-8cd8-42db-a28a-7854e6a95ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# hyper_params = {\n",
    "#     'penalty': ['l1', 'l2'],\n",
    "#     'class_weight': [None, 'balanced'],\n",
    "#     'max_iter': [500, 1000, 30]\n",
    "# }\n",
    "\n",
    "\n",
    "# a = hyper_params.values()\n",
    "# combinations = list(itertools.product(*a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35c015-8512-40b4-b56c-e6b51b6b0da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcdfc14-3ad0-4cf4-965a-ff6309fed4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cf1b003-b34f-433a-a901-2075a16c551c",
   "metadata": {},
   "source": [
    "##### Trying different approach to rescue grid search!\n",
    "\n",
    "- To get GridSearchCV to fit and return the score for the full dataset, we need to use a predefined split with one copy of the data fro training and another copy for validation.\n",
    "- We need to create our own scoring function with the correct signature (i.e. no need for y_true), as below.\n",
    "- Need to make sure refit=False\n",
    "- Need to make sure that random state is the same for each split ???\n",
    "\n",
    "#### The following is basically working, but needs converting the hdbscan and different scoring metrics...\n",
    "#### Also needs porting to scikit-optimize...Note: you need to specifiy the search space differently. \n",
    "\n",
    "#### And we need to add pipeline that includes a dim reduction algo.\n",
    "\n",
    "### Necessary to downgrade numpy to <1.24 because skopt uses np.int :/\n",
    "\n",
    "### Questions: should DVBC score use local value of 'metric' - problematic for comparing across different runs...\n",
    "\n",
    "DCBV not working with CV....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fff5d24-7ef8-4767-983d-911aad5f61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b576aaeb-c715-4bbc-9134-a545354738aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrusty-chris\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/expert/Documents/contracting/LCC/PLR/Chris/wandb/run-20230930_131750-c4ncqeno</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rusty-chris/test_clulster/runs/c4ncqeno' target=\"_blank\">run1</a></strong> to <a href='https://wandb.ai/rusty-chris/test_clulster' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rusty-chris/test_clulster' target=\"_blank\">https://wandb.ai/rusty-chris/test_clulster</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rusty-chris/test_clulster/runs/c4ncqeno' target=\"_blank\">https://wandb.ai/rusty-chris/test_clulster/runs/c4ncqeno</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "        name='run1',\n",
    "        project='test_clulster',\n",
    "        config={}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd02219-a516-4e22-b1d5-c0433a81ce24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e6e9b1b-4be2-4057-a26a-84039a75f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.concat([df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe429f92-6f36-4d55-afa4-bb5efa1956e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = PredefinedSplit([0 if i < len(df) else 1 for i in range(len(ddf.index))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc746d52-a04f-41ec-b2f1-2469e1fa3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = np.array([0 if i < len(df) else 1 for i in ddf.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "231b984a-9123-404d-9e43-605d58a36ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0d6ded5-e6e7-4fef-a729-3feb6e5d03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb = hdbscan.HDBSCAN(gen_min_span_tree=True, core_dist_n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49c4344f-fc06-4308-8f84-8814cc9e1d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_init='auto', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1407638-72cf-41cc-ab2f-1020076744a4",
   "metadata": {},
   "source": [
    "## Note: getting overflow in this version of DBCV when distances are small. Is there another implementation we can use?\n",
    "\n",
    "Note: this code may not work for n_jobs!=1 because of the way we obtain the iterations number from the length of the otpimisation result.\n",
    "\n",
    "#### Note: have to downgrade to skopt==0.8.1 and sklearn=0.24.2 for correct behaviour!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a40c2f0-8de3-476e-9b04-1cb2d7863368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: these scores use model.steps[1][1].labels_ instead of model.steps.labels_ because\n",
    "# they are accessing the clustering model which is the second step in the pipeline.\n",
    "\n",
    "# GLOBAL_BEST_SCORE = -1  # used because (it seems that) sometimes <X>SearchCV does not set best_score_ and best_params_ until the end of the run. So we track manually.\n",
    "\n",
    "def dbcv(data, labels, metric=None):\n",
    "    \n",
    "    if metric == None:\n",
    "        metric = model.steps[1][1].get_params()['metric']\n",
    "        \n",
    "    return hdbscan.validity.validity_index(\n",
    "            data, labels,\n",
    "            metric=metric\n",
    "        )\n",
    "    \n",
    "def silhouette(data, labels, metric):\n",
    "    num_labels = len(set(labels))\n",
    "    if num_labels == 1:\n",
    "        print(\"Warning: Valid number of clusters must be 2 or more.\")\n",
    "        return 0\n",
    "    else:\n",
    "        return silhouette_score(data, labels)\n",
    "\n",
    "# metrics.calinski_harabasz_score(X, labels)\n",
    "\n",
    "def cv_score(model, X, metric='euclidean', score='dbcv'):\n",
    "    \"\"\"\n",
    "    If score == 'all' we return a dictionary of all scores, which\n",
    "    can be logged to wandb on each iteration. \n",
    "\n",
    "    Otherwise this is intended for use as a scorer in <X>SearchCV methods.\n",
    "    In that case metric should be fixed to allow comparison across different runs.\n",
    "    \"\"\"\n",
    "    score_dict = {\n",
    "        'silhouette': silhouette,\n",
    "        'dbcv': dbcv\n",
    "    }\n",
    "    \n",
    "    model.fit(X)\n",
    "    return model.steps[1][1].relative_validity_\n",
    "    # labels = model.steps[1][1].labels_\n",
    "    # data = model.steps[0][1].transform(X)\n",
    "    # this_score = score_dict[score](data, labels, metric)\n",
    "\n",
    "    # # if not score == 'all' and this_score > GLOBAL_BEST_SCORE:\n",
    "    # #     GLOBAL_BEST_SCORE = this_score\n",
    "    \n",
    "    # return this_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc0d0abf-e3e2-432f-9343-4f6ab6e0a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'pca__n_components': Integer(5, 100),#, 30, 45, 60],\n",
    "    'hdbscan__min_samples': Integer(1,1000),\n",
    "    'hdbscan__min_cluster_size':Integer(10, 2000),  \n",
    "    'hdbscan__cluster_selection_method' : Categorical(['eom', 'leaf']),\n",
    "    'hdbscan__cluster_selection_epsilon' : Real(0.0, 100.0),\n",
    "    'hdbscan__metric' : Categorical(['euclidean', 'manhattan'])\n",
    "}\n",
    "\n",
    "# hyper_params = {\n",
    "#     'pca__n_components': [5, 15],#, 30, 45, 60],\n",
    "#     'kmeans__n_clusters': Integer(2, 20)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07247f54-a057-440c-80e0-259f5fb1e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('pca', pca), ('hdbscan', hdb)])\n",
    "# pipe = Pipeline(steps=[('pca', pca), ('kmeans', kmeans)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea5f6e32-6307-47ee-85c0-123916e6b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning = BayesSearchCV(\n",
    "   estimator=pipe,\n",
    "   search_spaces=hyper_params,\n",
    "   scoring=cv_score,\n",
    "   cv=split,\n",
    "   n_jobs=-1,\n",
    "   refit=False,\n",
    "   return_train_score=True,\n",
    "   n_iter=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60dedc78-362c-4012-8fc8-f3e2d22947d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add wandb logging. \n",
    "# Include labels_ and params and save to disk every X iterations... \n",
    "def get_best_score():\n",
    "    try:\n",
    "        best = tunning.best_score_\n",
    "    except:\n",
    "        best = np.nan\n",
    "    return best\n",
    "    \n",
    "def wandb_callback(result):\n",
    "    iter = len(result['x_iters'])\n",
    "    print('Iteration %d' %iter)\n",
    "    if iter > 1:\n",
    "        # try:\n",
    "            print(get_best_score())\n",
    "            print(\"Current params: \", tunning.cv_results_['params'][iter - 1])\n",
    "        # except:\n",
    "            # print(\"No best score found yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fce8dae4-9b84-41e0-9088-89438a143f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Iteration 2\n",
      "nan\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BayesSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtunning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mddf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(elapsed_time)\n",
      "File \u001b[0;32m~/Documents/contracting/LCC/PLR/Chris/venv/lib/python3.10/site-packages/skopt/searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs)\n\u001b[0;32m--> 466\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m~/Documents/contracting/LCC/PLR/Chris/venv/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/contracting/LCC/PLR/Chris/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/contracting/LCC/PLR/Chris/venv/lib/python3.10/site-packages/skopt/searchcv.py:518\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    512\u001b[0m     optim_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step(\n\u001b[1;32m    513\u001b[0m         search_space, optimizer,\n\u001b[1;32m    514\u001b[0m         evaluate_candidates, n_points\u001b[38;5;241m=\u001b[39mn_points_adjusted\n\u001b[1;32m    515\u001b[0m     )\n\u001b[1;32m    516\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[0;32m--> 518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43meval_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_result\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    519\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optim_results\u001b[38;5;241m.\u001b[39mappend(optim_result)\n",
      "File \u001b[0;32m~/Documents/contracting/LCC/PLR/Chris/venv/lib/python3.10/site-packages/skopt/utils.py:98\u001b[0m, in \u001b[0;36meval_callbacks\u001b[0;34m(callbacks, result)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m callbacks:\n\u001b[0;32m---> 98\u001b[0m         decision \u001b[38;5;241m=\u001b[39m \u001b[43mc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m decision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m             stop \u001b[38;5;241m=\u001b[39m stop \u001b[38;5;129;01mor\u001b[39;00m decision\n",
      "Cell \u001b[0;32mIn[60], line 16\u001b[0m, in \u001b[0;36mwandb_callback\u001b[0;34m(result)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(get_best_score())\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent params: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtunning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_results_\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28miter\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BayesSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "tunning.fit(ddf.to_numpy(), callback=wandb_callback)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "bf152e58-1187-4c62-a5f3-d234a0488b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunning.total_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d05fb19b-8301-47a4-a598-ed5fe628cd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunning.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "320d245a-9426-4ab1-81fb-47d01e7c0012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hdbscan__cluster_selection_epsilon', 4.46182243476504),\n",
       "             ('hdbscan__cluster_selection_method', 'leaf'),\n",
       "             ('hdbscan__metric', 'euclidean'),\n",
       "             ('hdbscan__min_cluster_size', 603),\n",
       "             ('hdbscan__min_samples', 382),\n",
       "             ('pca__n_components', 42)])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunning.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "9d5ce028-867e-4353-9549-8d0191404352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=42, random_state=42)),\n",
       "                (&#x27;hdbscan&#x27;,\n",
       "                 HDBSCAN(cluster_selection_epsilon=4.46182243476504,\n",
       "                         cluster_selection_method=&#x27;leaf&#x27;,\n",
       "                         gen_min_span_tree=True, min_cluster_size=603,\n",
       "                         min_samples=382))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=42, random_state=42)),\n",
       "                (&#x27;hdbscan&#x27;,\n",
       "                 HDBSCAN(cluster_selection_epsilon=4.46182243476504,\n",
       "                         cluster_selection_method=&#x27;leaf&#x27;,\n",
       "                         gen_min_span_tree=True, min_cluster_size=603,\n",
       "                         min_samples=382))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=42, random_state=42)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HDBSCAN</label><div class=\"sk-toggleable__content\"><pre>HDBSCAN(cluster_selection_epsilon=4.46182243476504,\n",
       "        cluster_selection_method=&#x27;leaf&#x27;, gen_min_span_tree=True,\n",
       "        min_cluster_size=603, min_samples=382)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(n_components=42, random_state=42)),\n",
       "                ('hdbscan',\n",
       "                 HDBSCAN(cluster_selection_epsilon=4.46182243476504,\n",
       "                         cluster_selection_method='leaf',\n",
       "                         gen_min_span_tree=True, min_cluster_size=603,\n",
       "                         min_samples=382))])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('pca', pca), ('hdbscan', hdb)])\n",
    "# pipe = Pipeline(steps=[('pca', pca), ('kmeans', kmeans)])\n",
    "pipe.set_params(**tunning.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "449cca87-8a96-4c72-94e4-801c3efa47b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_results_sanity_check(pipe, df, cv_results):\n",
    "\n",
    "    bs = tunning.best_score_\n",
    "    bp = tunning.best_params_\n",
    "    \n",
    "    pipe.set_params(**bp)\n",
    "\n",
    "    try:\n",
    "        assert bs == cv_score(pipe, df.to_numpy())\n",
    "    except:\n",
    "        print(bs, cv_score(pipe, df.to_numpy()))\n",
    "    bid = np.where(tunning.cv_results_['mean_test_score'] == bs)[0][0]\n",
    "\n",
    "    assert bp == tunning.cv_results_['params'][bid]\n",
    "    assert bs == tunning.cv_results_['split0_test_score'][bid]\n",
    "    assert bs == tunning.cv_results_['split1_test_score'][bid]\n",
    "    assert bs == tunning.cv_results_['split0_train_score'][bid]\n",
    "    assert bs == tunning.cv_results_['split1_train_score'][bid]\n",
    "\n",
    "    for i, s in enumerate(tunning.cv_results_['split0_test_score']):\n",
    "        assert (\n",
    "            s == tunning.cv_results_['split1_test_score'][i]\n",
    "        )\n",
    "\n",
    "    print(\"These search results passed all sanity checks. They are deterministic and consistent. :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "4ea321f8-90ed-4df0-87b8-a263f6848928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These search results passed all sanity checks. They are deterministic and consistent. :)\n"
     ]
    }
   ],
   "source": [
    "cv_results_sanity_check(pipe, df, tunning.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "f738283f-f35e-492d-9c66-e450f437b6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score(pipe, df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448ce12-2a0b-4873-ad8f-968d03411b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b81e6b-e983-4872-a83d-a6cbdf7a9034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414708b1-a81c-4f41-a305-16414c88debd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f70626-2cff-45e2-ba78-efd8ef4dc0a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MaskedArray' from 'sklearn.utils.fixes' (/home/expert/Documents/contracting/LCC/PLR/Chris/venv/lib/python3.10/site-packages/sklearn/utils/fixes.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesSearchCV\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_iris\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n",
      "File \u001b[0;32m~/Documents/contracting/LCC/PLR/Chris/venv/lib/python3.10/site-packages/skopt/__init__.py:55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gp_minimize\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msearchcv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesSearchCV\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Space\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dump\n",
      "File \u001b[0;32m~/Documents/contracting/LCC/PLR/Chris/venv/lib/python3.10/site-packages/skopt/searchcv.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_search\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSearchCV\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaskedArray\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m indexable, check_is_fitted\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MaskedArray' from 'sklearn.utils.fixes' (/home/expert/Documents/contracting/LCC/PLR/Chris/venv/lib/python3.10/site-packages/sklearn/utils/fixes.py)"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "searchcv = BayesSearchCV(\n",
    "    SVC(gamma='scale'),\n",
    "    search_spaces={'C': (0.01, 100.0, 'log-uniform')},\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "# callback handler\n",
    "def on_step(optim_result):\n",
    "    score = searchcv.best_score_\n",
    "    print(\"best score: %s\" % score)\n",
    "    if score >= 0.98:\n",
    "        print('Interrupting!')\n",
    "        return True\n",
    "\n",
    "\n",
    "searchcv.fit(X, y, callback=on_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b790c6-92c0-451d-a92e-0b0a9793fa50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
